{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a94a22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f90f7fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "# outputs = model(**inputs, labels=labels)\n",
    "# loss = outputs.loss\n",
    "# logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c61c2e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   word       5000 non-null   object \n",
      " 1   sentence1  5000 non-null   object \n",
      " 2   sentence2  5000 non-null   object \n",
      " 3   idx        5000 non-null   int64  \n",
      " 4   label      5000 non-null   bool   \n",
      " 5   start1     5000 non-null   int64  \n",
      " 6   start2     5000 non-null   int64  \n",
      " 7   end1       5000 non-null   int64  \n",
      " 8   end2       5000 non-null   int64  \n",
      " 9   version    5000 non-null   float64\n",
      "dtypes: bool(1), float64(1), int64(5), object(3)\n",
      "memory usage: 356.6+ KB\n",
      "0             Do you want to come over to my place later?\n",
      "1                                        Approach a task.\n",
      "2                                              Run rogue.\n",
      "3       The general ordered the colonel to hold his po...\n",
      "4                 We like to summer in the Mediterranean.\n",
      "                              ...                        \n",
      "4995       Art does not need to be innovative to be good.\n",
      "4996         He warned against the use of narcotic drugs.\n",
      "4997                              Change per unit volume.\n",
      "4998       They set out on their return to the base camp.\n",
      "4999                           They had a fierce wrestle.\n",
      "Name: sentence1, Length: 5000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "jsonObj = pd.read_json(path_or_buf='train.jsonl', lines=True)\n",
    "\n",
    "jsonObj.info()\n",
    "print(jsonObj['sentence1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2625424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def find_word_in_tokenized_sentence(word,token_ids):\n",
    "    decomposedWord = tokenizer(word)\n",
    "    # Iterate through to find a matching sublist of the token_ids\n",
    "    for i in range(len(token_ids)):\n",
    "        if token_ids[i] == decomposedWord[0] and token_ids[i:i+len(decomposedWord)] == decomposedWord:\n",
    "            return (i,i+len(decomposedWord)-1)\n",
    "    # This is the ouput when no matching pattern is found\n",
    "    return (-1,-1)\n",
    "  \n",
    "def find_words_in_tokenized_sentences(wordList,token_ids):\n",
    "    intList = []\n",
    "    for word in wordList:\n",
    "        if len(intList) == 0:\n",
    "            intList.append(find_word_in_tokenized_sentence(word,token_ids))\n",
    "        else:\n",
    "            afterLastInterval = intList[-1][1]+1\n",
    "            interv = find_word_in_tokenized_sentence(word,token_ids[afterLastInterval:])\n",
    "            actualPositions = (interv[0] + afterLastInterval,interv[1]+afterLastInterval)\n",
    "            intList.append(actualPositions)\n",
    "    return intList\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels, return_predict_correctness = False):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    if return_predict_correctness:\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat), pred_flat == labels_flat\n",
    "    else:\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def flat_predictions(preds):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    return pred_flat == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20f8fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre process Data for training here:\n",
    "batch_words = jsonObj['word'].astype(str).values.tolist()\n",
    "batch_idx = jsonObj['idx'].astype(str).values.tolist()\n",
    "batch_label = jsonObj['label'].astype(str).values.tolist()\n",
    "\n",
    "batch_sentences = jsonObj['sentence1'].astype(str).values.tolist()\n",
    "batch_of_second_sentences = jsonObj['sentence2'].astype(str).values.tolist()\n",
    "\n",
    "encoded_inputs = tokenizer(batch_sentences, batch_of_second_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33747c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
